<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>


<head>
    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript">google.load("jquery", "1.3.2");</script>

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/css/bootstrap.min.css">
      <!-- Custom styles for this template -->
        
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.0/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/js/bootstrap.min.js"></script>
  <link rel="stylesheet" type="text/css" href="styles.css">
    <!-- <link rel="icon" href="img/lightcommands.png"> -->
</head>


<!-- End : Google Analytics Code-->
<script type="text/javascript" src="../js/hidebib.js"></script>
<!-- <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic'
      rel='stylesheet' type='text/css'> -->
<head>
    <title>Sound of Interference</title>
    <meta property="og:description" content="Sound of Interference: Electromagnetic Eavesdropping Attack on Digital Microphones Using Pulse Density Modulation"/>
    <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Embed Audio</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Google Drive Video Embed</title>

    <!-- <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:creator" content="@ArashVahdat">
    <meta name="twitter:title" content="Diffusion Models for Adversarial Purification">
    <meta name="twitter:description"
          content="We propose <i>DiffPure</i> that uses diffusion models for adversarial purification.">
    <meta name="twitter:image" content=""> -->
</head>

<body>
    <div class="flex-row">
        <div class="paper-title text-center">
            <h1 style="color:rgb(71, 132, 216); font-size:80px;"><strong>Sound of Interference</strong></h1>
        </div>
        <div class="paper-title text-center">
            <h1 style="color:rgb(71, 132, 216);"><strong>Electromagnetic Eavesdropping Attack on Digital Microphones Using Pulse Density Modulation</strong></h1>
        </div>
    
        <div id="authors" class="text-center">
            <div class="author-row">
                <div class="col-3 text-center"><span style="font-size:25px">Arifu Onishi</span><sup>¶</sup></div>
                <div class="col-3 text-center"><span style="font-size:25px">Sri Hrushikesh Varma Bhupathiraju</span><sup>*</sup></div>
                <div class="col-3 text-center"><span style="font-size:25px">Rishikesh Bhatt</span><sup>*</sup></div>
                <div class="col-2 text-center"><span style="font-size:25px">Sara Rampazzi</span><sup>*</sup></div>
                <div class="col-2 text-center"><span style="font-size:25px">Takeshi Sugawara</span><sup>¶</sup></div>
            </div>
        </div>
    
        <!-- <div class="container" style="width: 100%; margin-top: 1.5em; margin-bottom: 1.5em; display: flex; justify-content: center;">
            <div class="logo-container" style="display: flex; justify-content: center; align-items: center; gap: 40px; flex-wrap: wrap;">
                <div class="logo">
                    <a href="https://www.uec.ac.jp/eng/">
                        <img src="img/uec_logo.png" alt="UEC logo" style="width: 250px; height: auto; display: block;">
                    </a>
                </div>
                <div class="logo">
                    <a href="https://www.eng.ufl.edu/">
                        <img src="img/uf-cjc-logo.png" alt="University of Florida logo" style="width: 250px; height: auto; display: block;">
                    </a>
                </div>
            </div>
        </div> -->
        <div class="container">
            <div class="logo-container">
                <div class="logo">
                    <a href="https://www.uec.ac.jp/eng/">
                        <img src="img/uec_logo.png" alt="UEC logo" class="logo-img">
                    </a>
                </div>
                <div class="logo">
                    <a href="https://www.eng.ufl.edu/">
                        <img src="img/uf-cjc-logo.png" alt="University of Florida logo" class="logo-img">
                    </a>
                </div>
            </div>
        </div>
        
          
    </div>
    
    <div class="boxed">
        <div class="flex-row">
            <p> We present a novel electromagnetic (EM) side-channel attack that enables acoustic eavesdropping on devices using modern MEMS microphones. These microphones transmit audio via pulse-density modulation (PDM), where each harmonic of the digital pulses retains acoustic data. Using simple FM demodulation with standard radio receivers, an attacker can remotely recover the audio heard by the microphone—without any software compromise or physical access.
            </p>
    
            <div class="image-container">
                <img class="scale_img" src="img/fig1_new.png" style="max-width: 100%; height: auto; display: block; margin: auto;">
            </div>
            <br>
    
            <p> We validate the attack through real-world tests on various PDM microphones and devices, including laptops and smart speakers. The attack achieves up to 94.2% digit recognition accuracy from 2 meters away, even through a 25 cm concrete wall. Using speech-to-text APIs not trained on EM signals, we recover speech with as little as 14% error on the Harvard Sentences dataset. Comparable results are obtained using a low-cost copper tape antenna. We also show that existing defenses like resampling are ineffective and propose a new hardware mitigation based on clock randomization.
            </p>
        </div>
    
        <br>
        To appear in <a href="https://www.usenix.org/conference/usenixsecurity25">USENIX 2025</a>. The artifacts of this work, data collected through the SoI attack, and scripts to fine-tune and evaluate speech recognition and transcription models are available at <a href="https://zenodo.org/records/14736347">Zenodo</a>.
        <br><br>
    
        <!-- <div class="text-center">
            <a href="https://arxiv.org/pdf/2404.11815.pdf" class="myButton">Read the preprint</a>
        </div> -->
    
        <!-- <br>
        For any questions reach out to <a href="mailto:soundofinterference@gmail.com"> SoundOfInterference </a> -->
    </div>
    

    <section id="novelties">
        <h2>Attack Demonstration</h2>
        <hr>
    
        <div class="attack-demo">
            <div class="video-container">
                <figure>
                    <iframe src="https://drive.google.com/file/d/1ZIJ2xxa8j1NE1CYjHz3NU20yzAxWbXH4/preview" allowfullscreen></iframe>
                    <figcaption>Demonstration of the attack in a real-world scenario, where a cheap antenna made with copper foil is placed across the wall from the target device.</figcaption>
                </figure>
            </div>
    
            <div class="video-container">
                <figure>
                    <iframe src="https://drive.google.com/file/d/1xVZXRtjviPTR5jcohHPwF96jX5Qe25t_/preview" allowfullscreen></iframe>
                    <figcaption>Demonstration of the attack in a real-world scenario, where a cheap antenna made with copper foil is placed across the wall from the target device.</figcaption>
                </figure>
            </div>
        </div>
    </section>
    
    
    <section id="outdoor">
        <br>
        <h2>Threat Model</h2>
        <hr>
    
        <div class="threat-model">
            <p>
                In this work, we study eavesdropping attacks using EM emissions from PDM MEMS microphones. The attacker’s goal is to hear the victim’s conversation when traditional acoustic eavesdropping is impossible because the attacker is away from the victim, e.g., in a separate room. The attacker exploits EM emission at a certain frequency, from the microphone cable that transmits the PDM signal, thus the attacker hears what the microphone hears.
            </p>
            <p>
                We assume that the attacker knows that the target device (e.g., a laptop, a smart speaker) has a PDM microphone. The attacker can acquire such information from online documents (e.g., user manual). We also assume that the attacker can retrieve the vulnerable frequency of the EM emission as done in previous works. For example, the attacker can learn such frequencies by buying a similar device used by the victim.
            </p>
        </div>
    </section>
    

    <section id="Principles">
        <br>
        <h2>Attack Principles</h2>
        <hr>
    
        <div class="attack-principles">
            <p>
                Directly recovering the base-band digital signals is challenging unless there is a wide-band strong coupling. For example, TEMPEST Comeback [22] used 25 MHz bandwidth for recovering a slow serial digital communication, which is more than 1,000 times larger than the typical audio bandwidth. Can an attacker recover the original audio from a narrow sub-band typically available to attackers? We explore the relationship with a simulation.
            </p>
    
            <p>
                We build our simulation model on the MATLAB/Simulink platform using the Mixed Signal Blockset. We use a signal generator to generate a linear chirp that sweeps 1–100 Hz with 100 Hz/s. The result suggests that the original signal is preserved around every harmonic as a frequency modulation (FM). Thus, an attacker can potentially exploit this phenomenon to eavesdrop on information captured by the microphone.
            </p>
    
            <figure>
                <img class="principles-img" src="img/sim_real_time_domain-1.png" alt="Simulation Results">
                <figcaption>
                    Feasibility analysis results in the simulation environment (a)–(c) and in the real-world environment (d)–(f). (a) and (d) are the original acoustic signal. (b) and (e) are spectrograms of the narrow-band EM leakage, wherein the trace of peak frequency has strong correlation to the original chirp signal. (c) and (f) the acoustic signals recovered by applying FM demodulation to the narrow-band EM leakage.
                </figcaption>
            </figure>
        </div>
    
        <br><br>
    
        <div class="attack-experiment">
            <p>
                To verify our simulated attack principle on a real device, we extract the EM radiation signal from a Lenovo Thinkpad T480 laptop’s top microphones by placing a probe antenna on the back panel. A loudspeaker in front of the laptop generates sound, emulating speech from a laptop user picked up by the laptop microphone. The sound volume is 64 dB, typical of a conversation in an office environment. We observe the linear frequency sweep of the chirp signal in the FM demodulated signal, although there is amplitude attenuation in the higher frequency region and minor distortion.
            </p>
    
            <p>
                We repeat the same experiments by playing the Harvard Sentences dataset and evaluate the intelligibility of the reconstructed signal using three state-of-the-art transcription models: (i) the HuBERT transcription model (CTCSpeech), (ii) the Microsoft speech-to-text tool (STTMicrosoft), and (iii) the OpenAI speech-to-text tool (STTOpenAI). We achieve word error rates of 4.6%, 3.1%, and 2.6%, respectively.
            </p>
    
            <img class="section-img" src="img/thinkpad_probe-1-1.png" alt="ThinkPad Experiment" height="50%" weight="50%">
        </div>
    
        <br><br>
    </section>
    

<section id="Audio_1">
    <div class="audio-container">
        <div class="audio-item">
            <audio controls>
                <source src="audio/Original.wav" type="audio/mpeg">
                Your browser does not support the audio element.
            </audio>
            <figcaption><b>Original audio sample from the Harvard Sentences dataset</b></figcaption>
        </div>
        <div class="audio-item">
            <audio controls>
                <source src="audio/Feasibility.wav" type="audio/mpeg">
                Your browser does not support the audio element.
            </audio>
            <figcaption><b>Audio signal reconstructed from EM Radiation using probe antenna</b></figcaption>
        </div>
    </div>
</section>


<section id="principles">
    <h2>Attacker Capability</h2>
    <hr>

    <!-- Description Block -->
    <div class="content-block">
        <p>
            We study the attacker's capability to remotely discern the leaked signal from the noise by measuring the signal-to-noise ratio under different conditions, i.e., (i) volume, (ii) antennas, (iii) orientations, and (iv) distance.
        </p>
        <p>
            <b>Impact of antenna distance and orientation:</b> We place our laptop in an office space and measure the SNR using a probe antenna (A<sub>Probe</sub>), a loop antenna (A<sub>Loop</sub>) in three orientations (vertical, horizontal, and perpendicular), and a Yagi antenna (A<sub>Yagi</sub>) in two orientations (horizontal, vertical). We achieve 25 dB PSNR at the device's proximity and 11.59 dB PSNR at 25 cm. The Yagi antenna performs better beyond 25 cm.
        </p>
    </div>

    <!-- Image Block -->
    <div class="image-group">
        <figure>
            <img class="section-img" src="img/orientation-1.png" alt="Antenna Orientation">
            <figcaption>Examined antenna configurations (A<sub>Loop</sub> and A<sub>Yagi</sub>) for the SNR evaluation.</figcaption>
        </figure>
        <figure>
            <img class="section-img" src="img/snr_antenna.png" alt="SNR Antenna">
            <figcaption>SNR over distance for different antenna configurations. Optimal quality achieved for A<sub>Loop</sub> perpendicular in short-distance scenarios and A<sub>Yagi</sub> horizontal for long-range attacks.</figcaption>
        </figure>
    </div>

    <!-- Volume Impact -->
    <div class="content-block">
        <p>
            <b>Impact of volume:</b> We reduce the sound volume from 64 to 58 dB (from an office to a lab environment). We observe a threshold behavior where the audio quality factor degrades with decreasing volume. Beyond 10 cm, where PSNR drops below 0 dB, the degradation of sound quality becomes significant.
        </p>
    </div>

    <div class="image-group">
        <figure>
            <img class="section-img" src="img/sound_quality.png" alt="Sound Quality Impact">
            <figcaption>Sound quality degradation over increasing distances.</figcaption>
        </figure>
    </div>
</section>


<section id="evaluation">
    <h2>Evaluation</h2>
    <hr>

    <!-- Behind-the-Wall Scenario -->
    <div class="content-block">
        <p><b>Behind-the-wall scenario:</b> We assess the accuracy of executing the attack in two adjacent rooms separated by a plaster wall (≈15 cm thick). The victim's laptop is placed on one side, and the attacker places the A<sub>Loop</sub> antenna on the other side. We evaluate distances of 15, 20, and 25 cm.</p>
        <p>The speaker classification accuracy reaches 99% at 20 cm and drops to 97.3% at 25 cm, confirming the high intelligibility of the recorded leakage. We achieve a word error rate of 6.5%.</p>
    </div>

    <div class="image-group">
        <figure>
            <img class="section-img" src="img/behind_wall_scenario.png" alt="Behind-the-wall Scenario">
            <figcaption>Attacker eavesdropping on the target laptop through a 15 cm plasterboard wall.</figcaption>
        </figure>
        <figure>
            <img class="section-img" src="img/behind_wall_results.png" alt="Behind-the-wall Results">
            <figcaption>Classification accuracy and word error rate (WER) in behind-the-wall scenarios.</figcaption>
        </figure>
    </div>

    <!-- Audio Samples -->
    <div class="audio-group">
        <div class="audio-item">
            <audio controls>
                <source src="audio/Original.wav" type="audio/mpeg">
            </audio>
            <figcaption><b>Original audio sample</b></figcaption>
        </div>
        <div class="audio-item">
            <audio controls>
                <source src="audio/BW_Loop.wav" type="audio/mpeg">
            </audio>
            <figcaption><b>Reconstructed audio using loop antenna</b></figcaption>
        </div>
        <div class="audio-item">
            <audio controls>
                <source src="audio/BW_Copper.wav" type="audio/mpeg">
            </audio>
            <figcaption><b>Reconstructed audio using cheap copper foil antenna</b></figcaption>
        </div>
    </div>

    <hr>

    <!-- Long Distance Evaluation -->
    <div class="content-block">
        <p><b>Long Distance Evaluation:</b> We analyze intelligibility over a 1-meter distance using a horizontal A<sub>Yagi</sub> at 461.887 MHz. The classification accuracy reaches 96.0% at 1 meter and drops to 91.6% at 2 meters. Beyond 4 meters, recovery accuracy declines significantly.</p>
    </div>

    <div class="image-group">
        <figure>
            <img class="section-img" src="img/long_distance_results.png" alt="Long Distance Results">
            <figcaption>Classification accuracy with the A<sub>Yagi</sub> antenna placed in an adjacent room.</figcaption>
        </figure>
    </div>

    <figure>
        <img class="section-img" src="img/room_scenarios.png" alt="Room Scenarios">
        <figcaption>Evaluated room scenarios, including different victim device orientations, occlusion, and wall materials/thicknesses.</figcaption>
    </figure>
</section>

<section id="generality">
    <h2>Attack Generality</h2>
    <hr>

    <!-- Description Block -->
    <div class="content-block">
        <p>
            To assess the applicability and generality of our discovered vulnerability, we evaluate various victim devices containing
            PDM microphones, including (i) another laptop model from the same vendor (Lenovo ThinkPad L580), (ii) laptops from other vendors (ASUS Chromebook C204MA and Redacted Laptop), (iii) a smart speaker (Google Home), and (iv) a headset (Jabra Evolve2 40 SE). 
        </p>
        <p>
            The classification and transcription results are consistent among the tested laptops (ThinkPad T480, L580, and Chromebook C204MA), achieving >98.0% speech and digit classification rates and ≤19.0% WER. The Redacted Laptop and the smart speaker exhibit ≥86.0% speaker classification and ≥90.3% digit classification but higher WER. The Jabra headset achieves 10% digit classification, 13.8% speaker classification, and 100% WER, highlighting its weaker vulnerability. Despite these variations, the headset's signal was still reconstructable with an STOI of 0.5490 using the A<sub>Probe</sub> antenna, confirming its susceptibility.
        </p>
    </div>

    <!-- Audio Section (Structured in Rows) -->
    <div class="audio-group">
        <div class="audio-row">
            <div class="audio-item">
                <figcaption><b>Original audio sample (Harvard Sentences Dataset)</b></figcaption>
                <audio controls>
                    <source src="audio/Original.wav" type="audio/mpeg">
                </audio>
            </div>
            <div class="audio-item">
                <figcaption><b>Lenovo ThinkPad T480</b></figcaption>
                <audio controls>
                    <source src="audio/BW_Copper.wav" type="audio/mpeg">
                </audio>
            </div>
        </div>

        <div class="audio-row">
            <div class="audio-item">
                <figcaption><b>Lenovo ThinkPad L580</b></figcaption>
                <audio controls>
                    <source src="audio/BW_L580.wav" type="audio/mpeg">
                </audio>
            </div>
            <div class="audio-item">
                <figcaption><b>Chromebook C204MA</b></figcaption>
                <audio controls>
                    <source src="audio/BW_ASUS.wav" type="audio/mpeg">
                </audio>
            </div>
        </div>

        <div class="audio-row">
            <div class="audio-item">
                <figcaption><b>Google Home</b></figcaption>
                <audio controls>
                    <source src="audio/BW_GHome.wav" type="audio/mpeg">
                </audio>
            </div>
            <div class="audio-item">
                <figcaption><b>Redacted Laptop</b></figcaption>
                <audio controls>
                    <source src="audio/BW_Redacted.wav" type="audio/mpeg">
                </audio>
            </div>
        </div>

        <div class="audio-row">
            <div class="audio-item">
                <figcaption><b>Jabra Evolve2 40 SE Headset</b></figcaption>
                <audio controls>
                    <source src="audio/BW_Jabra.wav" type="audio/mpeg">
                </audio>
            </div>
        </div>
    </div>
</section>

<section id="countermeasure">
    <h2>Countermeasures</h2>
    <hr>

    <div class="content-block">
        <p><b>Sampling Rate Randomization:</b> As discussed in the paper, shielding cannot fully mitigate all PDM leakage frequencies, making such defense insufficient. Other proposed defenses, such as signal encryption or EM signal blinding, come at the cost of power consumption, performance overhead, and sophisticated hardware designs. Previous eavesdropping attacks have shown that sampling rate affects the reconstructed signal quality and attack performance. 

        Thus, a potential mitigation is to randomize or decimate the audio signal's sampling rate. We evaluate transcription and speech recognition performance at 8, 16, 32, 40, and 48 kHz. Our findings show that digit classification accuracy remains 96% at 8 kHz and 97% at 16 kHz, exceeding 99% for higher sampling rates. Similarly, WER decreases by a maximum of 0.07% across all tested rates.</p>

        <p><b>Clock Randomization:</b> Spread-Spectrum Clocking (SSC) is a viable hardware defense against SoI. SSC randomly jitters clock signals, making narrow-band EM side-channels difficult to exploit. Designers can implement SSC by replacing standard oscillators with commercial SSC clock generators.

        We examine clock frequency deviations of 0.0%, 0.1%, 0.3%, and 1.0%, which are lower than commercial SSC generators (e.g., ADI's DS1087L at 2-4%). The EM side-channel's sound quality significantly deteriorates as deviation increases, reducing STOI from 0.7254 to 0.0490 at 1.0% deviation. Meanwhile, the original microphone's performance remains stable (≈0.98 STOI), confirming SSC's effectiveness in mitigating the attack.</p>
    </div>
</section>

<section id="acknowledgments">
    <h2>Acknowledgments</h2>
    <hr>

    <div class="content-block">
        <p>This research was funded by the JSPS KAKENHI Grant Number 22H00519, JST CREST JPMJCR23M4, and a gift from Meta. 

        We thank the anonymous reviewers for their insightful feedback, Kohei Doi for the initial exploration that stimulated this work, and Daniel Olszewski & Tyler Tucker for proofreading support.</p>
    </div>
</section>

</body>
</html>
