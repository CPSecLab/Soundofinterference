<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>


<head>
    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript">google.load("jquery", "1.3.2");</script>

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/css/bootstrap.min.css">
      <!-- Custom styles for this template -->
        
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.0/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/js/bootstrap.min.js"></script>
    <!-- <link rel="icon" href="img/lightcommands.png"> -->
</head>
<style type="text/css">
    body {
        font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
        font-weight: 300;
        font-size: 17px;
        margin-left: auto;
        margin-right: auto;
        width: 70%;
    }

    h1 {
        font-weight: 300;
        line-height: 1.15em;
    }

    h2 {
        font-size: 2em;
    }

    a:link, a:visited {
        color: #00aeff;
        text-decoration: none;
    }

    a:hover {
        color: #208799;
    }

    b:link, b:visited {
        color: #00aeff;
        text-decoration: none;
    }

    b:hover {
        color: #208799;
    }

    h1, h2, h3 {
        text-align: center;
    }

    h1 {
        font-size: 40px;
        font-weight: 500;
    }

    h2 {
        font-weight: 400;
        margin: 16px 0px 4px 0px;
    }

    .paper-title {
        padding: 16px 0px 16px 0px;
    }

    section {
        margin: 32px 0px 32px 0px;
        text-align: justify;
        clear: both;
    }

    .col-5 {
        width: 20%;
        float: left;
    }

    .col-4 {
        width: 25%;
        float: left;
    }

    .col-3 {
        width: 33%;
        float: left;
    }

    .col-2 {
        width: 50%;
        float: left;
    }

    .col-1 {
        width: 100%;
        float: left;
    }

    .row, .author-row, .affil-row {
        overflow: auto;
    }

    .author-row, .affil-row {
        font-size: 26px;
    }

    .row {
        margin: 16px 0px 16px 0px;
    }

    .authors {
        font-size: 26px;
    }

    .affil-row {
        margin-top: 16px;
    }

    .teaser {
        max-width: 100%;
    }

    .text-center {
        text-align: center;
    }

    .screenshot {
        width: 80%;
        border: 1px solid #ddd;
    }

    .screenshot-el {
        margin-bottom: 1px;
    }

    hr {
        height: 1px;
        border: 0;
        border-top: 1px solid #ddd;
        margin: 0;
    }

    .material-icons {
        vertical-align: -6px;
    }

    p {
        line-height: 1.25em;
        text-align: justify;
    }

    .caption {
        font-size: 16px;
        /*font-style: italic;*/
        color: #666;
        text-align: center;
        margin-top: 4px;
        margin-bottom: 10px;
    }

    video {
        display: block;
        margin: auto;
    }

    figure {
        display: block;
        margin: auto;
        margin-top: 10px;
        margin-bottom: 10px;
    }

    #bibtex pre {
        font-size: 13.5px;
        background-color: #eee;
        padding: 16px;
    }

    .blue {
        color: #2c82c9;
        font-weight: bold;
    }

    .orange {
        color: #d35400;
        font-weight: bold;
    }

    .flex-row {
        display: flex;
        flex-flow: row wrap;
        justify-content: space-around;
        padding: 0;
        margin: 0;
        list-style: none;
    }
    .table {
	width:100%;
	border:1px solid color-form-highlight;
    }

    .spacer { height: 40px; }
    
    .table-header {
    	display:flex;
    	width:100%;
    	background:rgb(32, 126, 181);
    	padding:(half-spacing-unit * 1.5) 0;
    }
    
    .table-row {
    	display:flex;
    	width:100%;
    	padding:(half-spacing-unit * 1.5) 0;
    
    }
    
    .table-data, .header__item {
    	flex: 1 1 20%;
    	text-align:center;
    }
    
    .header__item {
    	text-transform:uppercase;
    }

    .paper-btn {
        position: relative;
        text-align: center;

        display: inline-block;
        margin: 8px;
        padding: 8px 8px;

        border-width: 0;
        outline: none;
        border-radius: 2px;

        background-color: #48b64e;
        color: white !important;
        font-size: 20px;
        width: 100px;
        font-weight: 600;
    }

    .paper-btn-parent {
        display: flex;
        justify-content: center;
        margin: 16px 0px;
    }

    .paper-btn:hover {
        opacity: 0.85;
    }

    .container {
        margin-left: auto;
        margin-right: auto;
        padding-left: 16px;
        padding-right: 16px;
    }
    .boxed {
				padding: 1em 2em 2em 2em;
				background-color: #F8F8F8;
				max-width: 90%;
				margin: 0 auto !important; 
				float: none !important; ;
	}
	.boxed_mini {
				padding: 0.5em 0.5em 0.5em 0.5em;
				max-width: 40%;
				background-color: #ECF9FF;
				
	}
    .container {
        display: flex; /* Use flexbox for layout */
    }

    .image-container {
        position: relative; /* Position container relatively */
        margin-right: 20px; /* Add spacing between images */
    }

    .number {
        position: absolute; /* Position number relatively */
        /* top: -5; /* Position at the top */
        /* left: -5; Position at the left */ 
        /* background-color: rgba(0, 0, 0, 0.5); Background color for visibility */
        color: rgb(11, 11, 11); /* Text color */
        padding: 2px 5px; /* Padding for better visibility */
        border-radius: 5px; /* Rounded corners */
        display: inline-block; /* Display inline */
        font-weight: bold; /* Increase boldness */
        /* font-size: 20px; Increase font size */
    }
    .gallery {
            display: flex;
            justify-content: space-around; /* Adjusts the spacing between images */
            align-items: flex-start; /* Aligns images to the top */
            gap: 20px; /* Adds space between the figures */
            flex-wrap: wrap; /* Allows wrapping on smaller screens */
        }
    figure {
            text-align: center;
            margin: 0;
        }
    figcaption {
            font-size: 14px;
            color: #131314;
        }

    .image {
        display: block; /* Make image a block element */
        max-width: 100%; /* Ensure image doesn't exceed container width */
    }

    .venue {
        /*color: #B6486F;*/
        font-size: 30px;

    }

    .myButton_l {
				display:inline-block;
				cursor:pointer;
				font-family: Montserrat,sans-serif;
				font-weight: bold;
				font-size:15px;
				letter-spacing: 0.1em;
				padding:10px 10px;
				text-decoration:none;
			}
    .audio-container {
            display: flex;
            justify-content: space-around; /* Ensures even spacing */
            align-items: center; /* Aligns audio players properly */
            gap: 40px; /* Adds space between the items */
            padding: 5px;
        }
    .audio-item {
            text-align: center; /* Centers the caption below the player */
        }

	.myButton {
				 background-color:#6fc7ee;
				-moz-border-radius:18px;
				-webkit-border-radius:18px;
				border-radius:18px;
				display:inline-block;
				cursor:pointer;
				color:#ffffff;
				font-family: Montserrat,sans-serif;
				font-weight: bold;
				font-size:25px;
				letter-spacing: 0.1em;
				padding:10px 50px;
				text-decoration:none;
			}
	.myButton:hover {
				background-color:#478fcc;
				color:#ffffff;
				
			} 
    .centered-list-container {
    text-align: center;
}

.centered-list {
    display: inline-block;
    text-align: left; /* This ensures bullets are aligned correctly */
    list-style-position: inside; /* This keeps bullets inside the list item */
    padding: 0;
}

.centered-list li {
    margin: 5px 0;
}

</style>

<!-- End : Google Analytics Code-->
<script type="text/javascript" src="../js/hidebib.js"></script>
<!-- <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic'
      rel='stylesheet' type='text/css'> -->
<head>
    <title>Sound of Interference</title>
    <meta property="og:description" content="Sound of Interference: Electromagnetic Eavesdropping Attack on Digital Microphones Using Pulse Density Modulation"/>
    <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Embed Audio</title>
    <!-- <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:creator" content="@ArashVahdat">
    <meta name="twitter:title" content="Diffusion Models for Adversarial Purification">
    <meta name="twitter:description"
          content="We propose <i>DiffPure</i> that uses diffusion models for adversarial purification.">
    <meta name="twitter:image" content=""> -->
</head>

<body>
<div class="flex-row">
    <center>
    <div class="paper-title">
        <h1 style="color:rgb(71, 132, 216)"><span style="font-size:80px"><strong>Sound of Interference</strong></span></h1>
    </div>
    <div class="paper-title">
        <h1 style="color:rgb(71, 132, 216)"><strong>Electromagnetic Eavesdropping Attack on Digital Microphones Using Pulse Density Modulation</strong></h1>
    </div>

    <div id="authors">
        
            <div class="author-row">
                <div class="col-3 text-center"><span style="font-size:25px">Arifu Onishi</span><sup>Â¶</sup></div>
                <div class="col-3 text-center"><span style="font-size:25px">Sri Hrushikesh Varma Bhupathiraju</span><sup>*</sup></div>
                <div class="col-3 text-center"><span style="font-size:25px">Rishikesh Bhatt</span><sup>*</sup></div>
                <div class="col-2 text-center"><span style="font-size:25px">Sara Rampazzi</span><sup>*</sup></div>
                <div class="col-2 text-center"><span style="font-size:25px">Takeshi Sugawara</span><sup>Â¶</sup></div>
            </div>
            </div>
        </center>

        <center>
        <div class="container" style="width:100%;margin-top: 1.5em; margin-bottom: 1.5em; display:flex;justify-content:space-around;align-items:center; flex-wrap: wrap;">
                <div class="col-2">
                    <a href="https://www.uec.ac.jp/eng/">
                        <img width="420px" src="img/uec_logo.png" alt="UEC logo" class="image" />
                  </a>
                
                </div>
                <div class="col-2">
                    <a href="https://www.eng.ufl.edu/">
                        <img width = "400px" src="img/uf-cjc-logo.png" alt="University of Florida logo" class="image" />
                      </a>
            </div>
            <br>
            <div class="container" style="width:100%;margin-top: 1.5em; margin-bottom: 1.5em; display:flex;justify-content:space-around;align-items:center; flex-wrap: wrap;">
        
            </center>

        
        
    </div>
    <div class="boxed">
    <div class="flex-row">
        <p> We introduce a novel electromagnetic (EM) side-channel attack that allows for acoustic eavesdropping on electronic devices. This method specifically targets modern digital microelectromechanical systems (MEMS) microphones, which transmit captured audio via pulse-density modulation (PDM), that translate the analog sound signal into the density of output pulses in the digital domain. We discover that each harmonic of these digital pulses retains acoustic information, allowing the original audio to be retrieved through simple FM demodulation using standard radio receivers.
            An attacker can exploit this phenomenon to capture what the victim microphone hears remotely without installing malicious software or tampering with the device.  </p>

        <center>
        
            <img class="scale_img" src = "img/fig1_new.png" width="100%" height="250vh"></img>
            <br>
            <br>
        </center>
    

<br> <br>
<p> We verify the vulnerability presence by conducting real-world evaluation on several PDM microphones and electronic devices, including laptops and smart speakers. For example, we demonstrate that the attack achieves up to 94.2\% accuracy in recognizing spoken digits, up to 2 meters from a victim laptop located behind a 25 cm concrete wall. We also evaluate the attacker capability to eavesdrop on speech using popular speech-to-text APIs (e.g., OpenAI) not trained on EM traces, achieving a maximum of 14% transcription error rate in recovering the Harvard Sentences dataset. We further demonstrate that similar accuracy can be achieved with a cheap and stealthy antenna made out of copper tape. We finally discuss the limited effectiveness of current defenses such as resampling, and we propose a new hardware defense based on clock randomization. </p>
<br>
</div>
<br>To appear in <a href="https://www.usenix.org/conference/usenixsecurity25">USENIX 2025</a>



<!-- <center>           
            <a href="https://arxiv.org/pdf/2404.11815.pdf" class="myButton">Read the preprint</a>
            
</center> -->


<br>For any questions reach out to <a href=mailto:âsoundofinterference@gmail.com"> SoundOfInterference </a> 

            <!-- <a href="#bibtex"  class=" myButton " data-toggle="collapse" role="button">
        Cite <i class="fa fa-quote-right" aria-hidden="true"></i></a>
            <div id="bibtex" style="margin-top: 1.5em;" class="collapse" align="left">
                <pre style="white-space: pre"> -->

<!-- @inproceedings{sheldon2024aquasonic,

}
                </pre> -->
            
        

    </div>	

    
</div>

<section id="novelties"/>
    <h2>Attack Demonstration</h2>
    <hr>

	
	<div class="col-2 text-center"> <figure style="width: 100%">
        <center>           
            <video width="70%" 
               height="40%" 
               controls="controls">
        <source 
                src=
"video/wall_demo.mp4" 
                type="video/mp4" />
       </video>
       <br>

       <figcaption>Demonstration of the attack in a real-world scenario, where a cheap antenna made with copper foil is placed across the wall from the target device.
    </figcaption>
            
</center>
       
    </figure>
    </div>
    <div class="col-2 text-center"> <figure style="width: 100%">
        <center>           
            <video width="70%" 
               height="40%" 
               controls="controls">
        <source 
                src=
"video/tuning_demo.mp4" 
                type="video/mp4" />
       </video>
       <br>

       <figcaption>Demonstration of our auto scanning process that sweeps and picks the vulnerable frequencies in Sound of Interference.
    </figcaption>
            
</center>
       
    </figure>
        <!-- <br>
		<br>
	 -->

</div>
<div class="overlayText">
                <center>
               

	
    </section>

    <section id="outdoor"/>
	
		<br>
    <h2>Threat Model</h2>
    <hr>
    <div class="flex-row">
        <p>
            <br>
            In this work, we study eavesdropping attacks using EM emissions from PDM MEMS microphones. The attackerâs goal is to hear the victimâs conversation when traditional acoustic eavesdropping is impossible because the attacker is away from the victim, e.g., in a separate room. The attacker exploits EM emission at a certain frequency, from the microphone cable that transmits the PDM signal, thus the attacker hears what the microphone hears. We assume that the attacker knows that the target device (e.g., a laptop, a smart speaker) has a PDM microphone. The attacker can acquire such information from online documents (e.g., user manual). We also assume that the attacker can retrieve the vulnerable frequency of the EM emission as done in previous works. For example, the attacker can learn such frequencies by buying a similar device used by the victim.
        </p>
    </div>

<section id="Principles"/>
<br>
<h2>Attack Principles</h2>
<hr>
<div class="flex-row">
    <p>
        <br>
        Directly recovering the base-band digital signals is challenging unless there is a wide-band strong coupling. For example, TEMPEST Comeback [22] used 25 MHz bandwidth for recovering a slow serial digital communication, which is more than 1,000 times larger than the typical audio bandwidth. Can an attacker recover the original audio from a narrow sub-band typically available to attackers? We explore the relationship with a simulation.
        </p>
        <p>
        <br>
        We build our simulation model on the MATLAB/Simulink platform using the Mixed Signal Blockset. We use a signal generator to generate a linear chirp that sweeps 1â100 Hz with 100 Hz/s. The result suggests that the original signal is preserved around every harmonic as a frequency modulation (FM). Thus an attacker can potentially exploit this phenomenon to eavesdrop on information captured by the microphone.
    </p>
        <figure style="margin-top: 10px; margin-bottom: 10px;">
            <center><img width="100%" src="img/sim_real_time_domain-1.png"></center>
        <div class="overlayText">
                <br>
                <center>
                    <figcaption>Feasibility analysis results in the simulation environment (a)â(c) and in the real-world environment (d)â(f). (a) and (d) are the original acoustic signal. (b) and (e) are spectrograms of the narrow-band EM leakage, wherein the trace of peak frequency has strong correlation to the original chirp signal. (c) and (f) the acoustic signals recovered by applying FM demodulation to the narrow-band EM leakage
                    </figcaption>
                    </center>
            </div>
        </center>
    </figure>
</div>


    <br>
    <br>

    <div class="col-2 text-center">
        <img src="img/thinkpad_probe-1-1.png" alt="Description" width="65%" height="30%">
    </div>
        <div class="col-2 text-center">
            <p>To verify our simulated attack principle on a real device, we extract the EM radiation signal from a Lenovo Thinkpad T480 laptop top microphones, by placing a probe antenna on the back panel. A loud speaker in the front of the laptop generates sound, which, emulating speech from a laptop user picked up by the laptop microphone. The sound volume is 64 dB, typical of a conversation in an office environment.  We observe the linear frequency sweep of the chirp signal, in the FM demodulated signal although there is amplitude attenuation in higher frequency region and minor distortion.</p>

            <p>We repeat the same experiments with by playing the Harvard Sentences dataset and evaluate the intelligibility of the reconstructed signal using three state-of-the-art transcription models (i) the HuBERT transcription model (CTCSpeech), (ii) the Microsoft speech-to-text tool (STTMicrosoft), and (iii) the OpenAI speech-to-text tool (STTOpenAI).  We achieve word error rates of 4.6%, 3.1%, and 2.6% respectively.</p>


    </div>

    <br>
    <br>
</section>

<section id="Audio_1"/>


<div class="audio-container">
    <div class="audio-item">
        <audio controls>
            <source src="audio/Original.wav" type="audio/mpeg">
            Your browser does not support the audio element.
        </audio>
        <p><b>Original audio sample from the Harvard Sentences dataset</b></p>
    </div>

    <div class="audio-item">
        <audio controls>
            <source src="audio/Feasibility.wav" type="audio/mpeg">
            Your browser does not support the audio element.
        </audio>
        <p><b>Audio signal reconstructed from EM Radiation using probe antenna</b></p>
    </div>
</div>
</section>


<section id="Principles"/>
<br>
<h2>Attacker Capability</h2>
<hr>

<div class="flex-row">
    <p>
        <br>
        We study the attackerâs capability to remotely discern the leaked signal from the noise by measuring the signal-to-noise ratio under different conditions, i.e., (i) volume, (ii) antennas, (iii) orientations, and (iv) distance. 
    </p>
    <p>
        <b>Impact of antenna distance and orientation:</b> To measure the signal quality at increasing distances, we place our laptop in an office space and measure the SNR using a probe antenna (A<sub>Probe</sub>), a loop antenna (A<sub>Loop</sub>) in three different orientations (vertical, horizontal, and perpendicular), and a Yagi antenna (A<sub>Yagi</sub>) in two orientations (horizontal, and vertical).  We achieve 25 dB PSNR at the device's proximity and 11.59 dB PSNR, 25 cm from the device. The Yagi antenna performs better, beyond 25 cm.
    </p>
</div>
<br>
<div class="col-2 text-center">
<figure>
    <img class="scale_img" src = "img/orientation-1.png" width="90%" height="250vh"></img>
    <figcaption>Examined antenna configurations (A<sub>Loop</sub> and A<sub>Yagi</sub>) for the SNR evaluation (0 cm distance).</figcaption>
</figure>
</div>


<div class="col-2 text-center">
    <figure>
        <img class="scale_img" src = "img/snr_antenna.png" width="90%" height="250vh"></img>
        <figcaption>SNR over distance for different antenna configurations in our setup. The optimal signal quality is achieved for A<sub>Loop</sub> perpendicular in short-distance scenarios and A<sub>Yagi</sub> horizontal for long-range attacks.</figcaption>
    </figure>
    <br>
</div>

<br>

<div class="col-2 text-center">
    <br>
    <p><b>Impact of volume:</b> We reduce the sound volume from 64 to 58 dB (from office environment to a laboratory environment). We observe a threshold behavior in which the audio quality factor degradation is across sound volume for the benign microphone recording and EM side-channel recording at 0 & 5 cm. With recording beyond 10 cm, where PSNR becomes lower than 0 dB, the degradation of sound quality becomes more significant. FM-modulated EM leakage has high sensitivity in terms of small sound. However, beyond the threshold, the demodulated audio becomes noisy, and small sound becomes unintelligible.
    </p>
    </div>
    
    
    <div class="col-2 text-center">
        <br>
            <img class="scale_img" src = "img/sound_quality.png" width="80%" height="220vh"></img>
    </div>
    
</section>

<section id="evaluation"/>
<br>
<h2>Evaluation</h2>
<hr>

<div class="col-2 text-center">
    <br>
    <p> <b>Behind-the-wall scenario:</b> Here, we assess the accuracy of executing the attack in two adjacent rooms separated by a plaster wall with â15 cm thickness, as illustrated in the figure to the right. The victimâs laptop is placed on the other side of the wall, and the attacker locates the ALoop antenna on the other side of the wall. We evaluate the positioning of the laptop relative to the wall at distances of 15, 20, and 25 cm. 
    </p>
    <p> The speaker classification accuracy instead reaches 99% at 20 cm from the wall and slightly drops to 97.3% when the distance is 25 cm, revealing the high intelligibility of the recorded leakage. We achieve a word error rate of 6.5% in the behind-the-wall scenario when the target device is placed 20 cm from the wall.
    </p>
    <p> <b>Cheap and stealthy antenna:</b> Here, we evaluate the performance of SoI using an improvised antenna to show a simple and cheap attack execution for a more stealthy scenario. We build a cheap antenna AFoil made of standard copper foil tape (3M Embossed Copper Foil Conductive Tape 2245). Both ends of the tape are connected to a preamplifier, just as the other antennas (Mini-Circuits ZFL-1000LN+ ) have simple alligator clips. With this setup, we repeat the behind-the-wall attack scenarios. Despite the cheap antenna's unprecise design, the results reveal high accuracy for speaker and digit recognition and transcription rates.
    </p>
    </div>
    
    
    <div class="col-2 text-center">
        <br>
        <figure>
            <img class="scale_img" src = "img/behind_wall_scenario.png" width="80%" height="200vh"></img>
            <figcaption>Behind-the-wall scenario. Attacker eavesdrops the target laptop with an</figcaption> 
                <figcaption>antenna through 15 cm plasterboard wall, separating the victim and the attacker.</figcaption>
        </figure>
        <br>
        <figure>
            <img class="scale_img" src = "img/behind_wall_results.png" width="80%" height="200vh"></img>
            <figcaption>Digit and speaker classification results and WER in our behind-the-wall scenarios.</figcaption>
            <figcaption>The Lenovo T480 laptop was placed at 15, 20, and 25 cm from the antenna.</figcaption>
        </figure>
    </div>

    <div class="audio-container">
        <div class="audio-item">
            <audio controls>
                <source src="audio/Original.wav" type="audio/mpeg">
                Your browser does not support the audio element.
            </audio>
            <figcaption><b>Original audio sample from the Harvard Sentences dataset</b></figcaption>
        </div>
    
        <div class="audio-item">
            <audio controls>
                <source src="audio/BW_Loop.wav" type="audio/mpeg">
                Your browser does not support the audio element.
            </audio>
            <figcaption><b>Audio signal reconstructed using a loop antenna in behind the wall scenario</b></figcaption>
        </div>

        <div class="audio-item">
            <audio controls>
                <source src="audio/BW_Copper.wav" type="audio/mpeg">
                Your browser does not support the audio element.
            </audio>
            <figcaption><b>Audio signal reconstructed using a cheap copper foil antenna in behind the wall scenario</b></figcaption>
        </div>
    </div>
    <hr>
    <br>
    <div class="col-2 text-center">
    <p> <b>Long Distance Evaluation:</b> To evaluate the intelligibility of the captured sound over a 1-meter distance through a plasterboard wall using the horizontal A<sub>Yagi</sub> at 461.887 MHz, which achieved the best PSNR. We play the FSDD dataset from the speaker at 64 dB near the microphones. 
    </p>
    <p> The table to the right summarizes the classification accuracy over increasing distances compared to our baseline results measured with AProbe. The models achieve a classification accuracy of 96.0% and 96.1% for digit and speaker recognition, respectively, at 1 m distance and 91.6% and 92.5% at 2 meters. These distances are longer than the wavelength of the target frequency (â65 cm), suggesting the presence of far-field EM leakage. The recovery became challenging beyond 4 meters, with an accuracy drop below 10.6% for digit classification and 15.0% for speaker classification.  Based on this analysis, the attacker can recover audio with high accuracy (above 96%) within 2 meters from the victim device based on our experimental setup and antenna characteristics.
    </p>
</div>

<div class="col-2 text-center">
    <figure>
        <img class="scale_img" src = "img/long_distance_results.png" width="90%" height="220vh"></img>
        <figcaption>Long-distance digits and speaker classification accuracy with the A<sub>Yagi</sub> antenna placed in an adjacent room at 1â4 meters away. The table also shows the baseline result using A<sub>Probe</sub> placed on the target laptop.</figcaption>
            <figcaption></figcaption> 
    </figure>
    <br>
</div>

<figure>
    <br>
    <img class="scale_img" src = "img/room_scenarios.png" width="90%" height="250vh"></img>
    <figcaption>Evaluated room scenarios which include different victim device orientations, occlusion, and wall materials/thicknesses.</figcaption>
</figure>

</section>

<section id="generality"/>
<br>
<h2>Attack Generality</h2>
<hr>

<div class="col-2 text-center">
    <br>
    <p> To assess the applicability and generality of our discovered vulnerability, we evaluate various victim devices containing
        PDM microphones, in particular, (i) another laptop model
        from the same vendor (Lenovo ThinkPad L580 [58]), (ii) laptops from other vendors (ASUS Chromebook C204MA [12]
        and Redacted Laptop, (iii) a smart speaker (Google Home),
        and (iv) a headset (Jabra Evolve2 40 SE [44]). For each device,
        we use the same experimental setup with attacker behind the wall
        and the evaluation methodology of Section 4.4. For each target, we repeat the frequency scan over 25-512 MHz with a
        spectrum analyzer and discover the most efficient frequencies.
            </p>
    <p> The obtained classification and transcription results are substantially consistent and high among three tested
        laptops (ThinkPad T480, ThinkPad L580, and Chromebook
        C204MA), with > 98.0% speech and digit classification rates
        and â¤ 19.0% WER. The Redacted Laptop1 and the smart
        speaker instead show high speaker (â¥ 86.0%) and digit classification (â¥ 90.3%) accuracies but higher WER. We 
        hypothesize that this is because of multiple coupling paths in the
        devices in near-field. The signal reconstructed from the Jabra
        headset instead archives 10% and 13.8% digit and speaker
        classification accuracy, respectively, and 100% WER across
        all three transcription models. Despite these limitations, the
        signal can still be reconstructed with an STOI of 0.5490 using
        the more accurate AProbe antenna, confirming the vulnerability of the headset. We believe the reduced signal quality in the
        behind-the-wall scenario is attributed to the headset microphoneâs internal design, specifically the use of shorter-length
        cables. These results show the vulnerability widespread on consumer devices containing PDM
        microphones, raising concern over the possibility of eavesdropping on sensitive information. 
           </p>
</div>

<div class="col-2 text-center">
<div class="audio-container">
    <div class="audio-item">
        <figcaption><b>Original audio sample from the Harvard Sentences dataset</b></figcaption>
        <audio controls>
            <source src="audio/Original.wav" type="audio/mpeg">
            Your browser does not support the audio element.
        </audio>
    </div>
    </div>
    <div class="audio-container">
    <div class="audio-item">
        <figcaption><b>Audio Reconstructed from Lenovo ThinkPad T480</b></figcaption>
        <audio controls>
            <source src="audio/BW_Copper.wav" type="audio/mpeg">
            Your browser does not support the audio element.
        </audio>
    </div>
    </div>
    <div class="audio-container">
    <div class="audio-item">
        <figcaption><b>Audio Reconstructed from Lenovo ThinkPad T580</b></figcaption>
        <audio controls>
            <source src="audio/BW_L580.wav" type="audio/mpeg">
            Your browser does not support the audio element.
        </audio>
    </div>
</div>
<div class="audio-container">
    <div class="audio-item">
        <figcaption><b>Audio Reconstructed from Chromebook C204MA</b></figcaption>
        <audio controls>
            <source src="audio/BW_ASUS.wav" type="audio/mpeg">
            Your browser does not support the audio element.
        </audio>
    </div>
    </div>
<div class="audio-container">
    <div class="audio-item">
        <figcaption><b>Audio Reconstructed from Google Home</b></figcaption>
        <audio controls>
            <source src="audio/BW_GHome.wav" type="audio/mpeg">
            Your browser does not support the audio element.
        </audio>
    </div>
    </div>

<div class="audio-container">
    <div class="audio-item">
        <figcaption><b>Audio Reconstructed from Redacted Laptop</b></figcaption>
        <audio controls>
            <source src="audio/BW_Redacted.wav" type="audio/mpeg">
            Your browser does not support the audio element.
        </audio>
    </div>
    </div>
    <div class="audio-container">
        <div class="audio-item">
            <figcaption><b>Audio Reconstructed from Jabra Evolve2 40 SE Headset </b></figcaption>
            <audio controls>
                <source src="audio/BW_Jabra.wav" type="audio/mpeg">
                Your browser does not support the audio element.
            </audio>
        </div>
        </div>
</div>

<section id="countermeasure"/>
<br>
<h2>Countermeasures</h2>
<hr>

<br>
<div class="flex-row">
    <p><b>Sampling Rate Randomization:</b> As discussed in the paper, shielding cannot fully mitigate all the frequencies of the PDM leakage, making such defense insufficient. Other proposed defenses, such as signal encryption or EM signal blinding, come at the cost of power consumption, performance overhead, and more sophisticated application or hardware designs. Previous eavesdropping attacks have demonstrated that the signal sampling rate can influence the reconstructed signal quality and the subsequent eavesdropping performance. Thus, one possible way to mitigate the attack is to decimate or randomize the sampling rate of the audio signal itself. We evaluate the performance of transcription and speech recognition models by resampling the data at 8, 16, 32, 40, and 48 kHz. We observe that the digit classification model achieves a classification accuracy of 96% and 97% at 8 and 16 kHz sampling rates, respectively, and > 99% for the above sampling rates  Similarly, for speech transcription, we observe that the WER drops by a maximum of 0.07% for all the tested sampling rates. 
    
    </p>
    
    <p> <b>Clock Randomization:</b> Spread-spectrum clocking (SSC) can be an efficient hardware defense against SoI. SSC uses a clock signal with a random jitter, where high-frequency harmonics move randomly, making narrow-band EM side-channel a âmoving target.â Hardware designers can implement this approach by replacing a standard clock oscillator with commercially available SSC clock generators. We examine the frequency deviation by (a) 0.0%, (b) 0.1%, (c) 0.3%, and (d) 1.0%, which are smaller than that of practical SSC generators, e.g., 2% or 4% in ADIâs DS1087L. The sound quality of the EM side-channel drops significantly with clock deviation, changing from 0.7254 to 0.0490 with a 1.0% deviation. Meanwhile, the benign microphone recording remains at â0.98, unaffected by the clock deviation. As a result, clock randomization efficiently mitigates the attack without damaging the original microphone performance.
    
    </p>

</div>

<section id="acknowlegments"/>
<br>
<h2>Acknowledgments</h2>
<hr>

<br>
<div class="flex-row">
    <p>This research was funded by the JSPS KAKENHI Grant Number 22H00519, JST CREST JPMJCR23M4, and a gift from Meta. We thank the anonymous reviewers for the insightful comments, Kohei Doi for the initial exploration that stimulated this work, Daniel Olszewski and Tyler Tucker for the help in proofreading.  
</p>
<br>
</div>

</body>
</html>