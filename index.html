<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>


<head>
    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript">google.load("jquery", "1.3.2");</script>

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/css/bootstrap.min.css">
      <!-- Custom styles for this template -->
        
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.0/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/js/bootstrap.min.js"></script>
  <link rel="stylesheet" type="text/css" href="styles.css">
    <!-- <link rel="icon" href="img/lightcommands.png"> -->
</head>


<!-- End : Google Analytics Code-->
<script type="text/javascript" src="../js/hidebib.js"></script>
<!-- <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic'
      rel='stylesheet' type='text/css'> -->
<head>
    <title>Sound of Interference</title>
    <meta property="og:description" content="Sound of Interference: Electromagnetic Eavesdropping Attack on Digital Microphones Using Pulse Density Modulation"/>
    <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Embed Audio</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Google Drive Video Embed</title>

    <!-- <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:creator" content="@ArashVahdat">
    <meta name="twitter:title" content="Diffusion Models for Adversarial Purification">
    <meta name="twitter:description"
          content="We propose <i>DiffPure</i> that uses diffusion models for adversarial purification.">
    <meta name="twitter:image" content=""> -->
</head>

<body>
    <div class="flex-row">
        <div class="paper-title text-center">
            <h1 style="color:rgb(71, 132, 216); font-size:80px;"><strong>Sound of Interference</strong></h1>
        </div>
        <div class="paper-title text-center">
            <h1 style="color:rgb(71, 132, 216);"><strong>Electromagnetic Eavesdropping Attack on Digital Microphones Using Pulse Density Modulation</strong></h1>
        </div>
    
        <div id="authors" class="text-center">
            <div class="author-row">
                <div class="col-3 text-center"><span style="font-size:25px">Arifu Onishi</span><sup>¶</sup></div>
                <div class="col-3 text-center"><span style="font-size:25px">Sri Hrushikesh Varma Bhupathiraju</span><sup>*</sup></div>
                <div class="col-3 text-center"><span style="font-size:25px">Rishikesh Bhatt</span><sup>*</sup></div>
                <div class="col-2 text-center"><span style="font-size:25px">Sara Rampazzi</span><sup>*</sup></div>
                <div class="col-2 text-center"><span style="font-size:25px">Takeshi Sugawara</span><sup>¶</sup></div>
            </div>
        </div>
    
        <!-- <div class="container" style="width: 100%; margin-top: 1.5em; margin-bottom: 1.5em; display: flex; justify-content: center;">
            <div class="logo-container" style="display: flex; justify-content: center; align-items: center; gap: 40px; flex-wrap: wrap;">
                <div class="logo">
                    <a href="https://www.uec.ac.jp/eng/">
                        <img src="img/uec_logo.png" alt="UEC logo" style="width: 250px; height: auto; display: block;">
                    </a>
                </div>
                <div class="logo">
                    <a href="https://www.eng.ufl.edu/">
                        <img src="img/uf-cjc-logo.png" alt="University of Florida logo" style="width: 250px; height: auto; display: block;">
                    </a>
                </div>
            </div>
        </div> -->
        <div class="container">
            <div class="logo-container">
                <div class="logo">
                    <a href="https://www.uec.ac.jp/eng/">
                        <img src="img/uec_logo.png" alt="UEC logo" class="logo-img">
                    </a>
                </div>
                <div class="logo">
                    <a href="https://www.eng.ufl.edu/">
                        <img src="img/uf-cjc-logo.png" alt="University of Florida logo" class="logo-img">
                    </a>
                </div>
            </div>
        </div>
        
          
    </div>
    
    <div class="boxed">
        <div class="flex-row">
            <p> We present a novel electromagnetic (EM) side-channel attack that enables acoustic eavesdropping on devices using modern MEMS microphones. These microphones transmit audio via pulse-density modulation (PDM), where each harmonic of the digital pulses retains acoustic data. Using simple FM demodulation with standard radio receivers, an attacker can remotely recover the audio heard by the microphone—without any software compromise or physical access.
            </p>
    
            <div class="image-container">
                <img class="scale_img" src="img/fig1_new.png" style="max-width: 100%; height: auto; display: block; margin: auto;">
            </div>
            <br>
    
            <p> We validate the attack through real-world tests on various PDM microphones and devices, including laptops and smart speakers. The attack achieves up to 94.2% digit recognition accuracy from 2 meters away, even through a 25 cm concrete wall. Using speech-to-text APIs not trained on EM signals, we recover speech with as little as 14% error on the Harvard Sentences dataset. Comparable results are obtained using a low-cost copper tape antenna. We also show that existing defenses like resampling are ineffective and propose a new hardware mitigation based on clock randomization.
            </p>
        </div>
    
        <br>
        To appear in <a href="https://www.usenix.org/conference/usenixsecurity25">USENIX 2025</a>. The artifacts of this work, data collected through the SoI attack, and scripts to fine-tune and evaluate speech recognition and transcription models are available at <a href="https://zenodo.org/records/14736347">Zenodo</a>.
        <br><br>
    
        <!-- <div class="text-center">
            <a href="https://arxiv.org/pdf/2404.11815.pdf" class="myButton">Read the preprint</a>
        </div> -->
    
        <!-- <br>
        For any questions reach out to <a href="mailto:soundofinterference@gmail.com"> SoundOfInterference </a> -->
    </div>
    

    <section id="novelties">
        <h2>Attack Demonstration</h2>
        <hr>
    
        <div class="attack-demo">
            <div class="video-container">
                <figure>
                    <iframe src="https://drive.google.com/file/d/1ZIJ2xxa8j1NE1CYjHz3NU20yzAxWbXH4/preview" allowfullscreen></iframe>
                    <figcaption>Demonstration of the attack in a real-world scenario, where a cheap antenna made with copper foil is placed across the wall from the target device.</figcaption>
                </figure>
            </div>
    
            <div class="video-container">
                <figure>
                    <iframe src="https://drive.google.com/file/d/1xVZXRtjviPTR5jcohHPwF96jX5Qe25t_/preview" allowfullscreen></iframe>
                    <figcaption>Demonstration of the attack in a real-world scenario, where a cheap antenna made with copper foil is placed across the wall from the target device.</figcaption>
                </figure>
            </div>
        </div>
    </section>
    
    
<!--     <section id="outdoor">
        <br>
        <h2>Threat Model</h2>
        <hr>
    
        <div class="threat-model">
            <p>
                In this work, we study eavesdropping attacks using EM emissions from PDM MEMS microphones. The attacker’s goal is to hear the victim’s conversation when traditional acoustic eavesdropping is impossible because the attacker is away from the victim, e.g., in a separate room. The attacker exploits EM emission at a certain frequency, from the microphone cable that transmits the PDM signal, thus the attacker hears what the microphone hears.
            </p>
            <p>
                We assume that the attacker knows that the target device (e.g., a laptop, a smart speaker) has a PDM microphone. The attacker can acquire such information from online documents (e.g., user manual). We also assume that the attacker can retrieve the vulnerable frequency of the EM emission as done in previous works. For example, the attacker can learn such frequencies by buying a similar device used by the victim.
            </p>
        </div>
    </section> -->
    

    <section id="Principles">
        <br>
        <h2>Attack Principles</h2>
        <hr>
    
        <div class="attack-principles">
            <p>
                Recovering baseband digital signals typically requires wideband, strong coupling—e.g., TEMPEST Comeback used 25 MHz for low-rate serial data, far exceeding audio bandwidth. We investigate whether original audio can be recovered from the narrow sub-bands more commonly accessible to attackers through simulation.            
            </p>
            
            <p>
                Using MATLAB/Simulink with the Mixed Signal Blockset, we simulate a linear chirp (1–100 Hz at 100 Hz/s) and find that the original signal persists as FM around each harmonic. This indicates attackers could exploit these harmonics to eavesdrop on microphone-captured audio.            
            </p>
    
            <figure>
                <img class="principles-img" src="img/sim_real_time_domain-1.png" alt="Simulation Results">
                <figcaption>
                    Feasibility analysis results in the simulation environment (a)–(c) and in the real-world environment (d)–(f). (a) and (d) are the original acoustic signal. (b) and (e) are spectrograms of the narrow-band EM leakage, wherein the trace of peak frequency has strong correlation to the original chirp signal. (c) and (f) the acoustic signals recovered by applying FM demodulation to the narrow-band EM leakage.
                </figcaption>
            </figure>
        </div>
    
        <br><br>
    
        <div class="attack-experiment">
            <p>
                To validate our simulation, we extract EM signals from a Lenovo Thinkpad T480's microphones using a probe antenna on the back panel, while a speaker emits 64 dB speech-like audio. FM demodulation reveals the chirp’s frequency sweep, confirming the attack, despite some high-frequency attenuation and minor distortion.           
            </p>
            <p>
                We replay the Harvard Sentences and evaluate intelligibility using three transcription models—HuBERT (4.6% WER), Microsoft STT (3.1%), and OpenAI STT (2.6%)—demonstrating high reconstruction accuracy.            
            </p>
    
            <img class="section-img" src="img/thinkpad_probe-1-1.png" alt="ThinkPad Experiment" height="50%" weight="50%">
        </div>
    
        <br><br>
    </section>
    

<section id="Audio_1">
    <div class="audio-container">
        <div class="audio-item">
            <audio controls>
                <source src="audio/Original.wav" type="audio/mpeg">
                Your browser does not support the audio element.
            </audio>
            <figcaption><b>Original audio sample from the Harvard Sentences dataset</b></figcaption>
        </div>
        <div class="audio-item">
            <audio controls>
                <source src="audio/Feasibility.wav" type="audio/mpeg">
                Your browser does not support the audio element.
            </audio>
            <figcaption><b>Audio signal reconstructed from EM Radiation using probe antenna</b></figcaption>
        </div>
    </div>
</section>


<section id="principles">
    <h2>Attacker Capability</h2>
    <hr>

    <!-- Description Block -->
    <div class="content-block">
        <p>
            We assess the attacker's ability to extract signals by measuring SNR under varying volume, antenna types, orientations, and distances. Using a probe, loop, and Yagi antenna, we record up to 25 dB PSNR near the device and 11.59 dB at 25 cm, with the Yagi antenna outperforming others at longer ranges.
        </p>
    </div>

    <!-- Image Block -->
    <div class="image-group">
        <figure>
            <img class="section-img" src="img/orientation-1.png" alt="Antenna Orientation">
            <figcaption>Examined antenna configurations (A<sub>Loop</sub> and A<sub>Yagi</sub>) for the SNR evaluation.</figcaption>
        </figure>
        <figure>
            <img class="section-img" src="img/snr_antenna.png" alt="SNR Antenna">
            <figcaption>SNR over distance for different antenna configurations. Optimal quality achieved for A<sub>Loop</sub> perpendicular in short-distance scenarios and A<sub>Yagi</sub> horizontal for long-range attacks.</figcaption>
        </figure>
    </div>

    <!-- Volume Impact -->
    <div class="content-block">
        <p>
            Reducing volume from 64 dB to 58 dB reveals a threshold effect: audio quality significantly degrades when PSNR drops below 0 dB beyond 10 cm.   
        </p>
    </div>

    <div class="image-group">
        <figure>
            <img class="section-img" src="img/sound_quality.png" alt="Sound Quality Impact">
            <figcaption>Sound quality degradation over increasing distances.</figcaption>
        </figure>
    </div>
</section>


<section id="evaluation">
    <h2>Evaluation</h2>
    <hr>

    <!-- Behind-the-Wall Scenario -->
    <div class="content-block">
        <p><b>Behind-the-wall scenario:</b> We assess the accuracy of executing the attack in two adjacent rooms separated by a plaster wall (≈15 cm thick). The victim's laptop is placed on one side, and the attacker places the A<sub>Loop</sub> antenna on the other side. We evaluate distances of 15, 20, and 25 cm.</p>
        <p>The speaker classification accuracy reaches 99% at 20 cm and drops to 97.3% at 25 cm, confirming the high intelligibility of the recorded leakage. We achieve a word error rate of 6.5%.</p>
    </div>

    <div class="image-group">
        <figure>
            <img class="section-img" src="img/behind_wall_scenario.png" alt="Behind-the-wall Scenario">
            <figcaption>Attacker eavesdropping on the target laptop through a 15 cm plasterboard wall.</figcaption>
        </figure>
        <figure>
            <img class="section-img" src="img/behind_wall_results.png" alt="Behind-the-wall Results">
            <figcaption>Classification accuracy and word error rate (WER) in behind-the-wall scenarios.</figcaption>
        </figure>
    </div>

    <!-- Audio Samples -->
    <div class="audio-group">
        <div class="audio-item">
            <audio controls>
                <source src="audio/Original.wav" type="audio/mpeg">
            </audio>
            <figcaption><b>Original audio sample</b></figcaption>
        </div>
        <div class="audio-item">
            <audio controls>
                <source src="audio/BW_Loop.wav" type="audio/mpeg">
            </audio>
            <figcaption><b>Reconstructed audio using loop antenna</b></figcaption>
        </div>
        <div class="audio-item">
            <audio controls>
                <source src="audio/BW_Copper.wav" type="audio/mpeg">
            </audio>
            <figcaption><b>Reconstructed audio using cheap copper foil antenna</b></figcaption>
        </div>
    </div>

    <hr>

    <!-- Long Distance Evaluation -->
    <div class="content-block">
        <p><b>Long Distance Evaluation:</b> We analyze intelligibility over a 1-meter distance using a horizontal A<sub>Yagi</sub> at 461.887 MHz. The classification accuracy reaches 96.0% at 1 meter and drops to 91.6% at 2 meters. Beyond 4 meters, recovery accuracy declines significantly.</p>
    </div>

    <div class="image-group">
        <figure>
            <img class="section-img" src="img/long_distance_results.png" alt="Long Distance Results">
            <figcaption>Classification accuracy with the A<sub>Yagi</sub> antenna placed in an adjacent room.</figcaption>
        </figure>
    </div>

    <figure>
        <img class="section-img" src="img/room_scenarios.png" alt="Room Scenarios">
        <figcaption>Evaluated room scenarios, including different victim device orientations, occlusion, and wall materials/thicknesses.</figcaption>
    </figure>
</section>

<section id="generality">
    <h2>Attack Generality</h2>
    <hr>

    <!-- Description Block -->
    <div class="content-block">
        <p>
            To evaluate the generality of the vulnerability, we test multiple devices with PDM microphones, including laptops (Lenovo L580, ASUS Chromebook, Redacted), a smart speaker (Google Home), and a headset (Jabra Evolve2 40 SE).     
        </p>
        <p>
            Tested laptops show consistent performance with >98% classification accuracy and ≤19% WER. The smart speaker and Redacted Laptop achieve ≥86% speaker and ≥90.3% digit classification, but with higher WER. The Jabra headset shows limited vulnerability (10% digit, 13.8% speaker classification, 100% WER), yet remains susceptible with an STOI of 0.5490 using the AProbe antenna.       
        </p>
    </div>

    <!-- Audio Section (Structured in Rows) -->
    <div class="audio-group">
        <div class="audio-row">
            <div class="audio-item">
                <figcaption><b>Original audio sample (Harvard Sentences Dataset)</b></figcaption>
                <audio controls>
                    <source src="audio/Original.wav" type="audio/mpeg">
                </audio>
            </div>
            <div class="audio-item">
                <figcaption><b>Lenovo ThinkPad T480</b></figcaption>
                <audio controls>
                    <source src="audio/BW_Copper.wav" type="audio/mpeg">
                </audio>
            </div>
        </div>

        <div class="audio-row">
            <div class="audio-item">
                <figcaption><b>Lenovo ThinkPad L580</b></figcaption>
                <audio controls>
                    <source src="audio/BW_L580.wav" type="audio/mpeg">
                </audio>
            </div>
            <div class="audio-item">
                <figcaption><b>Chromebook C204MA</b></figcaption>
                <audio controls>
                    <source src="audio/BW_ASUS.wav" type="audio/mpeg">
                </audio>
            </div>
        </div>

        <div class="audio-row">
            <div class="audio-item">
                <figcaption><b>Google Home</b></figcaption>
                <audio controls>
                    <source src="audio/BW_GHome.wav" type="audio/mpeg">
                </audio>
            </div>
            <div class="audio-item">
                <figcaption><b>Redacted Laptop</b></figcaption>
                <audio controls>
                    <source src="audio/BW_Redacted.wav" type="audio/mpeg">
                </audio>
            </div>
        </div>

        <div class="audio-row">
            <div class="audio-item">
                <figcaption><b>Jabra Evolve2 40 SE Headset</b></figcaption>
                <audio controls>
                    <source src="audio/BW_Jabra.wav" type="audio/mpeg">
                </audio>
            </div>
        </div>
    </div>
</section>

<section id="countermeasure">
    <h2>Countermeasures</h2>
    <hr>

    <div class="content-block">
        <p><b>Sampling Rate Randomization:</b> Shielding is insufficient to fully mitigate PDM leakage, and other defenses like encryption or EM blinding incur power and performance costs. We explore sampling rate randomization as a mitigation, evaluating performance at 8, 16, 32, 40, and 48 kHz. Digit classification accuracy remains 96% at 8 kHz and 97% at 16 kHz, with WER improving slightly across all rates.
        </p>

        <p><b>Clock Randomization:</b> Spread-Spectrum Clocking (SSC) mitigates SoI by randomizing clock signals, making EM side-channels harder to exploit. We test deviations of 0.0%, 0.1%, 0.3%, and 1.0%, finding that as deviation increases, EM signal quality deteriorates (STOI drops from 0.7254 to 0.0490 at 1.0%). Meanwhile, the microphone’s performance remains stable (≈0.98 STOI), demonstrating SSC's effectiveness.
        </p>
    </div>
</section>

<section id="acknowledgments">
    <h2>Acknowledgments</h2>
    <hr>

    <div class="content-block">
        <p>This research was funded by the JSPS KAKENHI Grant Number 22H00519, JST CREST JPMJCR23M4, and a gift from Meta. 

        We thank the anonymous reviewers for their insightful feedback, Kohei Doi for the initial exploration that stimulated this work, and Daniel Olszewski & Tyler Tucker for proofreading support.</p>
    </div>
</section>

</body>
</html>
